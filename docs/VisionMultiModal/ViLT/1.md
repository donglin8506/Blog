

# ViLT

## 摘要

- 以前方法的做法：包含一个图片特征提取过程（image feature extraction processes）
    - 区域监督(region supervision)，即目标检测中的RPN等
    - 卷积架构(convolutional architecture)，即ResNet等结构

- 以前方法存在的问题
    - 效率(efficiency)/速度(speed)问题
        - 原因是: 由于需要使用backbone和RPN等组件提取图片特征，必然需要消耗时间
    - 表达能力(expressive power)问题     
        - 原因是: 由于只能去识别预定词库(predefined visual vocabulary)中的类别，自然就是有上限的。

- 本文方法
    - 完全去除图片特征提取过程，仅使用一个跟处理文本一样的Linear Embedding模块

- 本文方法的代码地址
    - https://github.com/dandelin/vilt


## 简介

- VLP方法的总体思想
    - 1. 利用配对的图片-文本，通过计算两者的相似度，来进行预训练，然后在下游任务上做微调
    - 2. 利用配对的图片-文本，通过掩码的方式，对图片或者文本做mask操作，然后对被masked的部分进行恢复，通过这种方式，来进行预训练，然后在下游任务上做微调