# 背景

整理一些需要学习的资料，以及待学习的资料或者有疑问的内容

概念关键词：人脸活体、OCR、芯算一体、Mixture-of-Experts (MoE)

待学习：

1. 自监督表征预训练CAE（Context Autoencoder）方法, 在隐含表征空间里，对掩码区域做预测；可以学习到语义表征，可用于图像块的检索

大模型训练的挑战和应对

共性：

模型大（例如GPT-3）、数据量大（例如十几亿图文对）、计算量大（64卡训练一个月）

差异：

- 网络结构有差别
- 模型稀疏性、稠密性有差别
- IO特性

Wide&Deep模型（万亿、稀疏）、Transformer类型预训练模型（千亿、稠密）、Mixture-of-Experts类多专家模型（万亿、十万亿、稠密）


难： ERNIE3.0 6.2E11 TFLOs / V100 32G 125TFLOPs

解决办法：


**多计算节点扩展（主动）**

- 保证收敛性（并行策略考虑计算等价性、正确性）
- 提升加速比（降低通信、同步等消耗）

**可训练：解决模型提及带来的挑战**
- 模型相关信息可被单计算设备存储下；
- 模型切分后可被正确、高效训练


数据并行策略，参数、梯度更新：参数服务器（中性化）、all Reduce（去中性化）等




======================================

大模型预NLP产业应用

- 新闻资讯推荐
- 智能客服对话
- 文档要素抽取 
- 智能文本审核
- 智能会议纪要
- 商品评价分析
- 舆情分析
- 机器人流程自动化
- 企业精准营销


背景：通用文本分类应用 不够用，更加场景化、更深入、更需要定制化开发。

存在一些问题：

- 场景化数据采集-标注困难
- 数据标准困难
- 研发成本高
- 应用场景窄，仅限于垂类，边际收益低


预训练大模型成为人工智能方向


效果好（NLP效果明显）、泛化能力强（GPT-3）、通用性强。

深度学习/大数据/大算力 + 自监督算法 + 少量数据微调的解决方案，来应用于业务。

大模型让AI成本大幅度降低：
- 标注数据量大幅降低，降低90%
- 计算资源大幅降低
- 研发周期大幅降低


大模型的工具和平台

- NLP开发套件 难
- BML-文本开发平台 中
- EasyDL-文本开发平台 易
- 智能文档分析（TextMind）
- 智能创作凭条
- 智能对话平台（UNIT）


NLP开发套件

推理和部署很关键，需要轻量化

ERNIE-Gen 【文本生成任务】对比同尺寸通用模型BLEU4提升2-5%
ERNIE-IE  【文本抽取任务】，适合零样本少样本情况，单标签5条样本
ERNIE-Rank 【检索排序任务】提升2%
ERNIE-Senta 【情感分析任务】，对比同尺寸通用模型平均提升0.6%
ERNIE-Sim 【文本匹配任务】对比同尺寸通用模型提升10%
ERNIE-Doc 【长文本分类匹配抽取任务】等
ERNIE-M 【多语言分类匹配抽取任务】等

常见NLP场景任务：
- 文本分类-单标签
- 文本分类-多标签
- 情感分析
- 文本匹配
- 序列标注
- 命名实体识别
- 机器阅读理解
- 中文问答
- 信息抽取
- 摘要生成
- 实体识别
- 关系抽取
- 文本生成
- 图文检索
- 富媒体抽取

