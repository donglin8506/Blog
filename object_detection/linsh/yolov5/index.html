
<!doctype html>
<html lang="zh" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
        <meta name="description" content="崔东林的技术积累">
      
      
        <meta name="author" content="崔东林">
      
      
        <link rel="canonical" href="https://donglin8506.github.io/Blog/object_detection/linsh/yolov5/">
      
      <link rel="icon" href="../../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.1, mkdocs-material-8.5.6">
    
    
      
        <title>Yolov5 - 从零实现</title>
      
    
    
      <link rel="stylesheet" href="../../../assets/stylesheets/main.20d9efc8.min.css">
      
        
        <link rel="stylesheet" href="../../../assets/stylesheets/palette.cbb835fc.min.css">
        
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#_1" class="md-skip">
          跳转至
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

<header class="md-header" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="页眉">
    <a href="../../.." title="从零实现" class="md-header__button md-logo" aria-label="从零实现" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            从零实现
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Yolov5
            
          </span>
        </div>
      </div>
    </div>
    
      <form class="md-header__option" data-md-component="palette">
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="default" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
          
            <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="m17.75 4.09-2.53 1.94.91 3.06-2.63-1.81-2.63 1.81.91-3.06-2.53-1.94L12.44 4l1.06-3 1.06 3 3.19.09m3.5 6.91-1.64 1.25.59 1.98-1.7-1.17-1.7 1.17.59-1.98L15.75 11l2.06-.05L18.5 9l.69 1.95 2.06.05m-2.28 4.95c.83-.08 1.72 1.1 1.19 1.85-.32.45-.66.87-1.08 1.27C15.17 23 8.84 23 4.94 19.07c-3.91-3.9-3.91-10.24 0-14.14.4-.4.82-.76 1.27-1.08.75-.53 1.93.36 1.85 1.19-.27 2.86.69 5.83 2.89 8.02a9.96 9.96 0 0 0 8.02 2.89m-1.64 2.02a12.08 12.08 0 0 1-7.8-3.47c-2.17-2.19-3.33-5-3.49-7.82-2.81 3.14-2.7 7.96.31 10.98 3.02 3.01 7.84 3.12 10.98.31Z"/></svg>
            </label>
          
        
          
          
          <input class="md-option" data-md-color-media="" data-md-color-scheme="slate" data-md-color-primary="indigo" data-md-color-accent="orange"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
          
            <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 7a5 5 0 0 1 5 5 5 5 0 0 1-5 5 5 5 0 0 1-5-5 5 5 0 0 1 5-5m0 2a3 3 0 0 0-3 3 3 3 0 0 0 3 3 3 3 0 0 0 3-3 3 3 0 0 0-3-3m0-7 2.39 3.42C13.65 5.15 12.84 5 12 5c-.84 0-1.65.15-2.39.42L12 2M3.34 7l4.16-.35A7.2 7.2 0 0 0 5.94 8.5c-.44.74-.69 1.5-.83 2.29L3.34 7m.02 10 1.76-3.77a7.131 7.131 0 0 0 2.38 4.14L3.36 17M20.65 7l-1.77 3.79a7.023 7.023 0 0 0-2.38-4.15l4.15.36m-.01 10-4.14.36c.59-.51 1.12-1.14 1.54-1.86.42-.73.69-1.5.83-2.29L20.64 17M12 22l-2.41-3.44c.74.27 1.55.44 2.41.44.82 0 1.63-.17 2.37-.44L12 22Z"/></svg>
            </label>
          
        
      </form>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="搜索" placeholder="搜索" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="查找">
        
        <button type="reset" class="md-search__icon md-icon" title="清空当前内容" aria-label="清空当前内容" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            正在初始化搜索引擎
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/donglin8506/Blog" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    donglin8506/Blog
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
            
<nav class="md-tabs" aria-label="标签" data-md-component="tabs">
  <div class="md-tabs__inner md-grid">
    <ul class="md-tabs__list">
      
        
  
  


  <li class="md-tabs__item">
    <a href="../../../Mkdocs/" class="md-tabs__link">
      mkdocs使用
    </a>
  </li>

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../deep_learning/transformer/" class="md-tabs__link">
        深度学习基础篇
      </a>
    </li>
  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../ObjectDetection/" class="md-tabs__link">
        目标检测篇
      </a>
    </li>
  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../VIT/paper_interpretation.md" class="md-tabs__link">
        目标分类
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    

  
  
  
    <li class="md-tabs__item">
      <a href="../../../VisionMultiModal/CLIP/paper_interpretation/" class="md-tabs__link">
        视觉多模态
      </a>
    </li>
  

  

      
        
  
  


  
  
  
    <li class="md-tabs__item">
      <a href="../../../Introduction.md" class="md-tabs__link">
        系统篇
      </a>
    </li>
  

      
    </ul>
  </div>
</nav>
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

  


<nav class="md-nav md-nav--primary md-nav--lifted" aria-label="导航栏" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../.." title="从零实现" class="md-nav__button md-logo" aria-label="从零实现" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    从零实现
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/donglin8506/Blog" title="前往仓库" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    donglin8506/Blog
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../../../Mkdocs/" class="md-nav__link">
        mkdocs使用
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_2" type="checkbox" id="__nav_2" checked>
      
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_2">
          深度学习基础篇
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="深度学习基础篇" data-md-level="1">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          深度学习基础篇
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../deep_learning/transformer/" class="md-nav__link">
        transformer介绍
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../deep_learning/conv2d/" class="md-nav__link">
        手动实现卷积
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_3" type="checkbox" id="__nav_3" checked>
      
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_3">
          目标检测篇
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="目标检测篇" data-md-level="1">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          目标检测篇
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../ObjectDetection/" class="md-nav__link">
        yolov5
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4" type="checkbox" id="__nav_4" checked>
      
      
      
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4">
          目标分类
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="目标分类" data-md-level="1">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          目标分类
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_4_1" type="checkbox" id="__nav_4_1" checked>
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_4_1">
          ViT
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="ViT" data-md-level="2">
        <label class="md-nav__title" for="__nav_4_1">
          <span class="md-nav__icon md-icon"></span>
          ViT
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../VIT/paper_interpretation.md" class="md-nav__link">
        论文详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../VIT/paper_read.md" class="md-nav__link">
        论文通读
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../VIT/paper_code/main.md" class="md-nav__link">
        代码阅读
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_5" type="checkbox" id="__nav_5" checked>
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5">
          视觉多模态
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="视觉多模态" data-md-level="1">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          视觉多模态
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_5_1" type="checkbox" id="__nav_5_1" checked>
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_1">
          CLIP
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="CLIP" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_1">
          <span class="md-nav__icon md-icon"></span>
          CLIP
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/CLIP/paper_interpretation/" class="md-nav__link">
        论文详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/CLIP/paper_read/" class="md-nav__link">
        论文通读
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/CLIP/paper_code/main/" class="md-nav__link">
        代码阅读
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_5_2" type="checkbox" id="__nav_5_2" checked>
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_2">
          MAE
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="MAE" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_2">
          <span class="md-nav__icon md-icon"></span>
          MAE
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/MAE/paper_interpretation/" class="md-nav__link">
        论文详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/MAE/paper_read/" class="md-nav__link">
        论文通读
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/MAE/paper_code/main.md" class="md-nav__link">
        代码阅读
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_5_3" type="checkbox" id="__nav_5_3" checked>
      
      
      
        
          
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_5_3">
          X-CLIP
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="X-CLIP" data-md-level="2">
        <label class="md-nav__title" for="__nav_5_3">
          <span class="md-nav__icon md-icon"></span>
          X-CLIP
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/X-CLIP/paper_interpretation/" class="md-nav__link">
        论文详解
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/X-CLIP/paper_read/" class="md-nav__link">
        论文通读
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../VisionMultiModal/X-CLIP/paper_code/main/" class="md-nav__link">
        代码阅读
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
        <input class="md-nav__toggle md-toggle md-toggle--indeterminate" data-md-toggle="__nav_6" type="checkbox" id="__nav_6" checked>
      
      
      
        
          
        
          
        
      
      
        <label class="md-nav__link" for="__nav_6">
          系统篇
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" aria-label="系统篇" data-md-level="1">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          系统篇
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../Introduction.md" class="md-nav__link">
        None
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../../cuidonglin/" class="md-nav__link">
        个人简介
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="目录">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      目录
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#_1" class="md-nav__link">
    说明
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#1" class="md-nav__link">
    1. 第一层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#2" class="md-nav__link">
    2. 第二层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#3" class="md-nav__link">
    3. 第三层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#4" class="md-nav__link">
    4. 第四层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#5-5" class="md-nav__link">
    5. 第5层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#6-6" class="md-nav__link">
    6. 第6层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#7-7" class="md-nav__link">
    7. 第7层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#8-8" class="md-nav__link">
    8. 第8层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#9-9" class="md-nav__link">
    9. 第9层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#10-10" class="md-nav__link">
    10. 第10层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#11-11" class="md-nav__link">
    11. 第11层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#12-12" class="md-nav__link">
    12. 第12层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#13-13" class="md-nav__link">
    13. 第13层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#14-14" class="md-nav__link">
    14. 第14层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#15-15" class="md-nav__link">
    15. 第15层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#16-16" class="md-nav__link">
    16. 第16层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#17-17" class="md-nav__link">
    17. 第17层
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#_2" class="md-nav__link">
    最后一层
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  <a href="https://github.com/donglin8506/Blog/edit/master/docs/object_detection/linsh/yolov5.md" title="编辑此页" class="md-content__button md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20.71 7.04c.39-.39.39-1.04 0-1.41l-2.34-2.34c-.37-.39-1.02-.39-1.41 0l-1.84 1.83 3.75 3.75M3 17.25V21h3.75L17.81 9.93l-3.75-3.75L3 17.25Z"/></svg>
  </a>


  <h1>Yolov5</h1>

<h2 id="_1">说明</h2>
<p>整理yolov5s的整体结构</p>
<h2 id="1">1. 第一层</h2>
<p>输入情况</p>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 1, 'Conv', [64, 6, 2, 2]]&quot;

args: [64, 6, 2, 2]
gd: 0.33
dw: 0.5
n = 1

m: models.common.Conv

c1, c2 = 3, 64
args: [3, 32, 6, 2, 2] # 经过更新; 32是64 * 0.5
m_ = m(*args)
</code></pre>
<p>模块代码</p>
<pre><code class="language-python">class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): 
        &quot;&quot;&quot;
        c1, c2, k, s, p = 3, 32, 6, 2, 2
        &quot;&quot;&quot;
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))
</code></pre>
<pre><code class="language-python">输出情况：
t: models.common.Conv
np: 3520 (参数量)
    - 计算方式：(卷积部分参数)3*32*6*6+(Bn参数)32+32= 3520
    - 包括卷积核的参数和BN层的两个参数
输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]    

from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv]     
ch: [32] # 当前循环结束后的值
</code></pre>
<h2 id="2">2. 第二层</h2>
<p>输入情况：</p>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 1, 'Conv', [128, 3, 2]]&quot;
f, n, m, args = -1, 1, 'Conv', [128, 3, 2]
m = eval(m) # models.common.Conv
n = n_ = 1

c1 = ch[-1] = 32 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 128 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 64 # 因为是s版本，所以要折半

args: [32, 64, 3, 2]

</code></pre>
<pre><code class="language-python">class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): 
        &quot;&quot;&quot;
        c1, c2, k, s, p = 32, 64, 3, 2, None
        &quot;&quot;&quot;
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))
# 参数量计算：c1 * c2 * k * k + c2

def autopad(k, p=None):  # kernel, padding
    # Pad to 'same'
    # k, p = 3, None 
    # p自动设置为 k的一半并向下取整
    if p is None:
        p = k // 2 if isinstance(k, int) else (x // 2 for x in k)  # auto-pad
    return p
</code></pre>
<p>输出情况：</p>
<pre><code class="language-python">t: 'models.common.Conv'
np: 18560 (参数量)
    - 计算方式：(卷积部分参数)32*64*3*3+(Bn参数)64+64= 18560
    - 包括卷积核的参数和BN层的两个参数
输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]  

from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv]     
ch: [32, 64] # 当前循环结束后的值
</code></pre>
<h2 id="3">3. 第三层</h2>
<p>输入情况：</p>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 3, 'C3', [128]]&quot;
f, n, m, args = -1, 3, 'C3', [128]
m = eval(m) # models.common.C3
n = n_ = 1 # 这里虽然原始n等于3，但由于是s版本，3 * .33 = 1，即还是1个C3模块

c1 = ch[-1] = 32 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 128 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 64 # 因为是s版本，所以要折半

args: [64, 64] # C3为什么只有通道数，没有卷积核这些参数
args: [64, 64, 1] # 执行过args.insert(2, n)的操作，所以最后一项变为1
</code></pre>
<pre><code class="language-python">class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    # 输入参数：[64, 64, 1] 输入和输出通道数，以及当前模块的堆叠个数；其他参数使用默认
    # 1.两个1x1卷积分成两部分；2.一部分经过Botteneck，一部分保持不变；3.Cat两部分；4. 最后经过一个1x1卷积
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n))) # 输入和输出通道数相等且e=1，这种情况能一直堆叠。
        # self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))
# C3的参数量计算：(64 * 32 * 1 * 1 + 32*2) + (64 * 32 * 1 * 1 + 32*2) + (64 * 64 * 1 * 1 + 64*2) + B = 8448 + B = 18816
class Bottleneck(nn.Module):
    # Standard bottleneck
    # 一个包含有 1x1卷积+3x3卷积+shortcut的块
    # 如果输入通道和输出通道数相等，则使用shortcut
    # 1x1卷积的输出通道数*e
    # 输入参数：[32, 32, e=1.0]
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
# Bottleneck参数量计算：(32 * 32 * 1 * 1 + 32*2) + (32 * 32 * 3 * 3 + 32*2) = 10368
</code></pre>
<p>输出情况：</p>
<pre><code class="language-python">t: 'models.common.C3'
np: 18816 (参数量)
    - 计算方式：(64 * 32 * 1 * 1 + 32*2) + (64 * 32 * 1 * 1 + 32*2) + (64 * 64 * 1 * 1 + 64*2) + (32 * 32 * 1 * 1 + 32*2) + (32 * 32 * 3 * 3 + 32*2) = 18816
    - 同上
输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2] # [c1, c2, k, s, p]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2] # [c1, c2, k, s]               
  2                -1  1     18816  models.common.C3                        [64, 64, 1] # [c1, c2, n]

from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3]     
ch: [32, 64, 64] # 当前循环结束后的值
</code></pre>
<h2 id="4">4. 第四层</h2>
<p>输入情况：</p>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 1, 'Conv', [256, 3, 2]]&quot;
f, n, m, args = -1, 1, 'Conv', [256, 3, 2]
m = eval(m) # models.common.Conv
n = n_ = 1  

c1 = ch[-1] = 64 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 256 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 128 # 因为是s版本，所以要折半

args: [64, 128] # C3为什么只有通道数，没有卷积核这些参数
args: [64, 128, 3, 2] 
</code></pre>
<pre><code class="language-python">class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): 
        &quot;&quot;&quot;
        c1, c2, k, s, p = 64, 128, 3, 2, None
        &quot;&quot;&quot;
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))
</code></pre>
<pre><code class="language-python">t: 'models.common.Conv'
np: 18816 (参数量)
    - 计算方式：64 * 128 * 3 * 3 + 128 * 2 = 73984

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2] # [c1, c2, k, s, p]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2] # [c1, c2, k, s]               
  2                -1  1     18816  models.common.C3                        [64, 64, 1] # [c1, c2, n]
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2] # [c1, c2, k, s]

from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv]     
ch: [32, 64, 64, 128] # 当前循环结束后的值
</code></pre>
<h2 id="5-5">5. 第5层</h2>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 6, 'C3', [256]]&quot;
f, n, m, args = -1, 6, 'C3', [256]
m = eval(m) # models.common.C3
n = n_ = 6 * 0.33 = 2

c1 = ch[-1] = 128 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 256 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 128 # 因为是s版本，所以要折半

args: [128, 128] # 
args: [128, 128, 2] 
</code></pre>
<pre><code class="language-python">class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    # 输入参数：[128, 128, 2] 输入和输出通道数，以及当前模块的堆叠个数；其他参数使用默认
    # 1.两个1x1卷积分成两部分；2.一部分经过Botteneck，一部分保持不变；3.Cat两部分；4. 最后经过一个1x1卷积
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n))) # 输入和输出通道数相等且e=1，这种情况能一直堆叠。
        # self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))
# C3的参数量计算：(128 * 64 * 1 * 1 + 64*2) * 2 + (128 * 128 * 1 * 1 + 128*2) + B = 33280 + B = 115712
class Bottleneck(nn.Module):
    # Standard bottleneck
    # 一个包含有 1x1卷积+3x3卷积+shortcut的块
    # 如果输入通道和输出通道数相等，则使用shortcut
    # 1x1卷积的输出通道数*e
    # 输入参数：[128, 128, e=1.0]
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
# Bottleneck参数量计算：(64 * 64 * 1 * 1 + 64*2) + (64 * 64 * 3 * 3 + 64*2) = 41216
# 两个Bottleneck : 41216 * 2 = 82432
</code></pre>
<pre><code class="language-python">t: 'models.common.C3'
np: 115712 (参数量)
    - 计算方式：上面

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2] # [c1, c2, k, s, p]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2] # [c1, c2, k, s]               
  2                -1  1     18816  models.common.C3                        [64, 64, 1] # [c1, c2, n]
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2] # [c1, c2, k, s]
  4                -1  2    115712  models.common.C3                        [128, 128, 2] # [c1, c2, n] n=2
from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3]     
ch: [32, 64, 64, 128, 128] # 当前循环结束后的值
</code></pre>
<h2 id="6-6">6. 第6层</h2>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 1, 'Conv', [512, 3, 2]]&quot;
f, n, m, args = -1, 1, 'Conv', [512, 3, 2]
m = eval(m) # models.common.Conv
n = n_ = 1

c1 = ch[-1] = 128 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 512 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 256 # 因为是s版本，所以要折半

args: [512, 3, 2] # 
args: [128, 256, 3, 2] 
</code></pre>
<pre><code class="language-python">class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): 
        &quot;&quot;&quot;
        c1, c2, k, s, p = 128, 256, 3, 2, None
        &quot;&quot;&quot;
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))
# 参数量： 128 * 256 * 3 * 3 + 256 * 2 = 295424
</code></pre>
<pre><code class="language-python">t: 'models.common.Conv'
np: 295424 (参数量)
    - 计算方式：上面

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2] # [c1, c2, k, s, p]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2] # [c1, c2, k, s]               
  2                -1  1     18816  models.common.C3                        [64, 64, 1] # [c1, c2, n]
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2] # [c1, c2, k, s]
  4                -1  2    115712  models.common.C3                        [128, 128, 2] # [c1, c2, n] n=2
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2] # [c1, c2, k, s]  
from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv]     
ch: [32, 64, 64, 128, 128, 256] # 当前循环结束后的值
</code></pre>
<h2 id="7-7">7. 第7层</h2>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 9, 'C3', [512]]&quot;
f, n, m, args = -1, 9, 'C3', [512]
m = eval(m) # models.common.C3
n = n_ = 9 * 0.33 = 3

c1 = ch[-1] = 256 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 512 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 256 # 因为是s版本，所以要折半

args: [256, 256] # 
args: [256, 256, 3] 
</code></pre>
<pre><code class="language-python">class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    # 输入参数：[256, 256, 3] 输入和输出通道数，以及当前模块的堆叠个数；其他参数使用默认
    # 1.两个1x1卷积分成两部分；2.一部分经过Botteneck，一部分保持不变；3.Cat两部分；4. 最后经过一个1x1卷积
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n))) # 输入和输出通道数相等且e=1，这种情况能一直堆叠。
        # self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))
# C3的参数量计算：(256 * 128 * 1 * 1 + 128*2) * 2 + (256 * 256 * 1 * 1 + 256*2) + B = 132096 + B = 625152
class Bottleneck(nn.Module):
    # Standard bottleneck
    # 一个包含有 1x1卷积+3x3卷积+shortcut的块
    # 如果输入通道和输出通道数相等，则使用shortcut
    # 1x1卷积的输出通道数*e
    # 输入参数：[128, 128, e=1.0]
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
# Bottleneck参数量计算：(128 * 128 * 1 * 1 + 128*2) + (128 * 128 * 3 * 3 + 128*2) = 164352
# 两个Bottleneck : 164352 * 3 = 493056
</code></pre>
<pre><code class="language-python">t: 'models.common.C3'
np: 625152 (参数量)
    - 计算方式：上面

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2] # [c1, c2, k, s, p]
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2] # [c1, c2, k, s]               
  2                -1  1     18816  models.common.C3                        [64, 64, 1] # [c1, c2, n]
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2] # [c1, c2, k, s]
  4                -1  2    115712  models.common.C3                        [128, 128, 2] # [c1, c2, n] n=2
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2] # [c1, c2, k, s]  
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv, C3]     
ch: [32, 64, 64, 128, 128, 256, 256] # 当前循环结束后的值
</code></pre>
<h2 id="8-8">8. 第8层</h2>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 1, 'Conv', [1024, 3, 2]]&quot;
f, n, m, args = -1, 1, 'Conv', [1024]
m = eval(m) # models.common.Conv
n = n_ = 1

c1 = ch[-1] = 256 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 1024 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 512 # 因为是s版本，所以要折半

args: [256, 512, 3, 2] # 
</code></pre>
<pre><code class="language-python">class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): 
        &quot;&quot;&quot;
        c1, c2, k, s, p = 256, 512, 3, 2, None
        &quot;&quot;&quot;
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))
# 参数量： 256 * 512 * 3 * 3 + 512 * 2 = 1180672
</code></pre>
<pre><code class="language-python">t: 'models.common.Conv'
np: 1180672 (参数量)
    - 计算方式：上面

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]          
from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv]     
ch: [32, 64, 64, 128, 128, 256, 256, 512] # 当前循环结束后的值
</code></pre>
<h2 id="9-9">9. 第9层</h2>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 3, 'C3', [1024]]&quot;
f, n, m, args = -1, 3, 'C3', [1024]]
m = eval(m) # models.common.C3
n = n_ = 3 * 0.33 = 1

c1 = ch[-1] = 512 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 1024 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 512 # 因为是s版本，所以要折半

args: [512, 512] # 
args: [512, 512, 1] 
</code></pre>
<pre><code class="language-python">class C3(nn.Module):
    # CSP Bottleneck with 3 convolutions
    # 输入参数：[512, 512, 1] 输入和输出通道数，以及当前模块的堆叠个数；其他参数使用默认
    # 1.两个1x1卷积分成两部分；2.一部分经过Botteneck，一部分保持不变；3.Cat两部分；4. 最后经过一个1x1卷积
    def __init__(self, c1, c2, n=1, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, number, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c1, c_, 1, 1)
        self.cv3 = Conv(2 * c_, c2, 1)  # optional act=FReLU(c2)
        self.m = nn.Sequential(*(Bottleneck(c_, c_, shortcut, g, e=1.0) for _ in range(n))) # 输入和输出通道数相等且e=1，这种情况能一直堆叠。
        # self.m = nn.Sequential(*(CrossConv(c_, c_, 3, 1, g, 1.0, shortcut) for _ in range(n)))

    def forward(self, x):
        return self.cv3(torch.cat((self.m(self.cv1(x)), self.cv2(x)), 1))
# C3的参数量计算：(512 * 256 * 1 * 1 + 256*2) * 2 + (512 * 512 * 1 * 1 + 512*2) + B = 526336 + B = 
class Bottleneck(nn.Module):
    # Standard bottleneck
    # 一个包含有 1x1卷积+3x3卷积+shortcut的块
    # 如果输入通道和输出通道数相等，则使用shortcut
    # 1x1卷积的输出通道数*e
    # 输入参数：[256, 256, e=1.0]
    def __init__(self, c1, c2, shortcut=True, g=1, e=0.5):  # ch_in, ch_out, shortcut, groups, expansion
        super().__init__()
        c_ = int(c2 * e)  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_, c2, 3, 1, g=g)
        self.add = shortcut and c1 == c2

    def forward(self, x):
        return x + self.cv2(self.cv1(x)) if self.add else self.cv2(self.cv1(x))
# Bottleneck参数量计算：(256 * 256 * 1 * 1 + 256*2) + (256 * 256 * 3 * 3 + 256*2) = 656384
</code></pre>
<pre><code class="language-python">t: 'models.common.C3'
np: 1182720 (参数量)
    - 计算方式：上面

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                            
from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3]     
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512] # 当前循环结束后的值
</code></pre>
<h2 id="10-10">10. 第10层</h2>
<p>是一种新层 SPPF</p>
<pre><code class="language-python">配置文件中的参数：&quot;[-1, 1, 'SPPF', [1024, 5]]&quot;
f, n, m, args = -1, 1, 'SPPF', [1024, 5]]
m = eval(m) # models.common.SPPF
n = n_ = 3 * 0.33 = 1

c1 = ch[-1] = 512 # 输入通道数，从上一层的输出通道数获取
c2 = args[0] = 1024 # 输出通道数，从当前层的配置文件中获取, 其中的第一项
c2 = c2 * 0.5 = 512 # 因为是s版本，所以要折半

args: [512, 512, 5] 
</code></pre>
<pre><code class="language-python">class SPPF(nn.Module):
    # Spatial Pyramid Pooling - Fast (SPPF) layer for YOLOv5 by Glenn Jocher
    # [512, 512, 5] 
    def __init__(self, c1, c2, k=5):  # equivalent to SPP(k=(5, 9, 13))
        super().__init__()
        c_ = c1 // 2  # hidden channels
        self.cv1 = Conv(c1, c_, 1, 1)
        self.cv2 = Conv(c_ * 4, c2, 1, 1)
        self.m = nn.MaxPool2d(kernel_size=k, stride=1, padding=k // 2)

    def forward(self, x):
        x = self.cv1(x)
        with warnings.catch_warnings():
            warnings.simplefilter('ignore')  # suppress torch 1.9.0 max_pool2d() warning
            y1 = self.m(x)
            y2 = self.m(y1)
            return self.cv2(torch.cat((x, y1, y2, self.m(y2)), 1))

# 参数量：(512 * 256 * 1 * 1 + 256 * 2) + (1024 * 512 * 1 * 1 + 512 * 2) = 656896
</code></pre>
<pre><code class="language-python">t: 'models.common.SPPF'
np: 656896 (参数量)
    - 计算方式：上面

输出打印情况：
                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                  
from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF]     
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512] # 当前循环结束后的值
</code></pre>
<h2 id="11-11">11. 第11层</h2>
<p>输入参数：</p>
<pre><code class="language-python">f, n, m, args = [-1, 1, 'Conv', [512, 1, 1]]
i = 10

c1 = ch[f] = 512
c2 = args[0] * 0.5 = 256
args = [512, 256, 1, 1]
t = 'models.common.Conv'
np = 131584
</code></pre>
<pre><code class="language-python">class Conv(nn.Module):
    # Standard convolution
    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True): 
        &quot;&quot;&quot;
        c1, c2, k, s, p = 512, 256, 1, 1, None
        &quot;&quot;&quot;
        super().__init__()
        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)
        self.bn = nn.BatchNorm2d(c2)
        self.act = nn.SiLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())

    def forward(self, x):
        return self.act(self.bn(self.conv(x)))

    def forward_fuse(self, x):
        return self.act(self.conv(x))
# 参数量： 512 * 256 * 1 * 1 + 256 * 2 = 131584
</code></pre>
<pre><code class="language-python">                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1] # [c1, c2, k, s]
 ```

 ```python
 from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv]     
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256] # 当前循环结束后的值
</code></pre>
<h2 id="12-12">12. 第12层</h2>
<p>Upsample层没有参数量，</p>
<pre><code class="language-python">i = 11
f, n, m, args = -1, 1, 'nn.Upsample', ['None', 2, 'nearest']

n = n_ = 1
c1 = 512 # c1没有发生变化
c2 = ch[f] # 256
t = 'torch.nn.modules.upsampling.Upsample'
</code></pre>
<pre><code class="language-python">                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']  

from: -1 # 含义是当前层的输入来自上一层的输出
save: [] # 因为当前层不会进行推理，所以不必保存
layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv, Upsample]     
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256] # 当前循环结束后的值

</code></pre>
<h2 id="13-13">13. 第13层</h2>
<p>Concat层没有参数</p>
<pre><code class="language-python">i = 12 
f, n, m, args = [[-1, 6], 1, 'Concat', [1]]
</code></pre>
<pre><code class="language-python">elif m in Concat:
    c2 = sum(ch[x] for x in f) = sum(ch[-1], ch[6]) = 512

class Concat(nn.Module):
    def __init__(self, dimension=1):
        super().__init__()
        self.d = dimension
    def forward(self, x):
        return torch.cat(x, self.d)
</code></pre>
<pre><code class="language-python">                 from  n    params  module                                  arguments                     
  0                -1  1      3520  models.common.Conv                      [3, 32, 6, 2, 2]              
  1                -1  1     18560  models.common.Conv                      [32, 64, 3, 2]                
  2                -1  1     18816  models.common.C3                        [64, 64, 1]                   
  3                -1  1     73984  models.common.Conv                      [64, 128, 3, 2]               
  4                -1  2    115712  models.common.C3                        [128, 128, 2]                 
  5                -1  1    295424  models.common.Conv                      [128, 256, 3, 2]              
  6                -1  3    625152  models.common.C3                        [256, 256, 3]                 
  7                -1  1   1180672  models.common.Conv                      [256, 512, 3, 2]              
  8                -1  1   1182720  models.common.C3                        [512, 512, 1]                 
  9                -1  1    656896  models.common.SPPF                      [512, 512, 5]                 
 10                -1  1    131584  models.common.Conv                      [512, 256, 1, 1]              
 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          
 12           [-1, 6]  1         0  models.common.Concat                    [1] 

from: [-1, 6] # 输入来自上一层和索引第6层
save: [6] # 第一个不等于-1的值
layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv, Upsample, Concat]     
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512] # 当前循环结束后的值
</code></pre>
<h2 id="14-14">14. 第14层</h2>
<pre><code class="language-python">i = 13
f, n, m, args = -1, 3, 'C3', [512, False]

args = [512, 256, False]
args = [512, 256, 1, False]
</code></pre>
<pre><code class="language-python">layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv, Upsample, Concat, C3] 
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256]
</code></pre>
<h2 id="15-15">15. 第15层</h2>
<pre><code class="language-python">i = 14
f, n, m, args = -1, 1, 'Conv', [256, 1, 1]

args = [256, 128, 1, 1]
</code></pre>
<pre><code class="language-python">layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv, Upsample, Concat, C3, Conv] 
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128]
</code></pre>
<h2 id="16-16">16. 第16层</h2>
<pre><code class="language-python">i = 15
f, n, m, args = -1, 1, 'nn.Upsamle', ['None', 2, 'nearest']

</code></pre>
<pre><code class="language-python">layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv, Upsample, Concat, C3, Upsample] 
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128]
</code></pre>
<h2 id="17-17">17. 第17层</h2>
<pre><code class="language-python">i = 16
f, n, m, args = [[-1, 4], 1, 'Concat', [1]]

</code></pre>
<pre><code class="language-python">layers: [Conv, Conv, C3, Conv, C3, Conv, C3, Conv, C3, SPPF, Conv, Upsample, Concat, C3, Upsample, Concat] 
ch: [32, 64, 64, 128, 128, 256, 256, 512, 512, 512, 256, 256, 512, 256, 128, 128]
</code></pre>
<h2 id="_2">最后一层</h2>
<p>Detect</p>
<pre><code class="language-python">i = 24
f, n, m, args = [17, 20, 23], 1, 'Detect', ['nc', 'anchors']

args = [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]]

args = [80, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [ch[17], ch[20], ch[23]]]

</code></pre>
<pre><code class="language-python">class Detect(nn.Module):
    stride = None  # strides computed during build
    onnx_dynamic = False  # ONNX export parameter
    export = False  # export mode

    def __init__(self, nc=80, anchors=(), ch=(), inplace=True):  # detection layer
        # nc = 80; anchors = [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]]
        # ch = [128, 256, 512]
        super().__init__()
        self.nc = nc  # number of classes
        self.no = nc + 5  # number of outputs per anchor
        self.nl = len(anchors)  # number of detection layers
        self.na = len(anchors[0]) // 2  # number of anchors
        self.grid = [torch.zeros(1)] * self.nl  # init grid
        self.anchor_grid = [torch.zeros(1)] * self.nl  # init anchor grid
        self.register_buffer('anchors', torch.tensor(anchors).float().view(self.nl, -1, 2))  # shape(nl,na,2)
        self.m = nn.ModuleList(nn.Conv2d(x, self.no * self.na, 1) for x in ch)  # output conv
        self.inplace = inplace  # use in-place ops (e.g. slice assignment)

self.nc = 80
self.no = nc + 5 = 85
self.nl = len(anchors) = 3
self.na = len(anchors[0]) // 2 = 3
self.grid = [torch.zeros(1)] * self.nl = [tensor([0.]), tensor([0.], tensor([0.]))] 
self.register_buffer('anchors', torch.tensor(anchors).float().view(self.nl, -1, 2)) # 第一项是层数nl；每层可以有多个anchor；但每个anchor都是有两个值
# [[[10, 13],
    [16, 30],
    [33, 23]],
   [[30, 61],
    [62, 45],
    [59, 119]],
   [[116, 90],
    [156, 198],
    [373, 326]]]
# shape (3, 3, 2)
</code></pre>
<hr />
<p>模型的推理过程：</p>
<pre><code class="language-python">def _forward_once(self, x):
    y, dt = [], []
    for m in self.model:
        if m.f != -1:
            x = y[m.f] if isinstance(x, int)
        x = m(x)
        y.append(x if m.i in self.save else None)
    return x
</code></pre>
<pre><code class="language-python">输入是[tensor(1,128,32,32), tensor(1, 256, 16, 16), tensor(1, 512, 8, 8)]
</code></pre>
<pre><code class="language-python">class Detect(nn.Module):
    ...
    def forward(self, x):
        # 输入是[tensor(1,128,32,32), tensor(1, 256, 16, 16), tensor(1, 512, 8, 8)]
        z = []
        for i in range(self.nl): # 几层特征图，3层
            x[i] = self.m[i](x[i]) # self.m[i] 由于self.m是一个nn.ModuleList，self.m[i]是其第i项；将第特征图tensor(1,128,32,32)传入到self.m[0]中; shape: [1, 128, 32, 32] -&gt; [1, 255, 32, 32]
            bs, _, ny, nx = x[i].shape # x[0].shape : [1, 255, 32, 32]
            # [1, 255, 32, 32] -&gt; [1, 3, 85, 32, 32] -&gt; [1, 3, 32, 32, 85]
            # 1: 一张图片的特征图
            # 3: 包括3种anchor
            # 32, 32: 32 x 32每个点上都有这么3种anchor
            # 85: 每个anchor有85种输出
            x[i] = x[i].view(bs, self.na, self.no, self.ny, self.nx).permute(0, 1, 3, 4, 2).contiguous()

i = 0 ; [1, 128, 32, 32] -&gt; [1, 255, 32, 32] -&gt; [1, 3, 32, 32, 85]
i = 1 ; [1, 256, 16, 16] -&gt; [1, 255, 16, 16] -&gt; [1, 3, 16, 16, 85]
i = 2 ; [1, 512, 8, 8]   -&gt; [1, 255, 8, 8]   -&gt; [1, 3, 8, 8, 85]
</code></pre>





                
              </article>
            </div>
          
          
        </div>
        
          <a href="#" class="md-top md-icon" data-md-component="top" hidden>
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            回到页面顶部
          </a>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
      Copyright &copy; 2022 Donglin Cui
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    <a href="https://github.com/donglin8506" target="_blank" rel="noopener" title="GitHub | Donglin-Cui" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2022 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../..", "features": ["navigation.tabs", "navigation.top", "navigation.indexes", "navigation.expand", "search.suggest", "search.highlight"], "search": "../../../assets/javascripts/workers/search.5bf1dace.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.config.lang": "ja", "search.config.pipeline": "trimmer, stemmer", "search.config.separator": "[\\s\\-\uff0c\u3002]+", "search.placeholder": "\u641c\u7d22", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version.title": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script>
    
    
      <script src="../../../assets/javascripts/bundle.078830c0.min.js"></script>
      
    
  </body>
</html>